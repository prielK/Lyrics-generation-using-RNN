{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics Generation Using RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Embedding, Concatenate, Reshape\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = \"glove.6B.300d.txt\"\n",
    "TRAIN_PATH = \"lyrics_train_set.csv\"\n",
    "TEST_PATH = \"lyrics_test_set.csv\"\n",
    "MIDI_PATH = \"midi_files\"\n",
    "MIDI_PKL_PATH = \"midi_df.pkl\"\n",
    "\n",
    "WORD_DIM = 300\n",
    "MAX_SEQUENCE_LENGTH = 14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for loading the dataset and creating the word2vec representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "    # Merge the lyrics columns\n",
    "    lyrics_cols = df.iloc[:, 3:].copy()\n",
    "    df = df.rename(columns={0: \"artist\", 1: \"title\", 2: \"lyrics\"})\n",
    "    df[\"lyrics\"] = lyrics_cols.apply(\"\".join, axis=1)\n",
    "    df = df[[\"artist\", \"title\", \"lyrics\"]]\n",
    "    # Cleans the lyrics\n",
    "    df[\"lyrics\"] = df[\"lyrics\"].apply(\n",
    "        lambda lyrics: re.sub(\"[^a-zA-Z &]\", \"\", lyrics).lower().strip()\n",
    "    )\n",
    "    df[\"lyrics\"] = df[\"lyrics\"].str.replace(\"chorus\", \"\")\n",
    "    df[\"lyrics\"] = df[\"lyrics\"].str.replace(\"verse\", \"\")\n",
    "    df[\"lyrics\"] = df[\"lyrics\"].str.replace(\"instrumental\", \"\")\n",
    "    df[\"lyrics\"] = df[\"lyrics\"].apply(lambda lyrics: re.sub(r\"\\s+\", \" \", lyrics))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_glove(path):\n",
    "    word2vec = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line_vals = line.split(\" \")\n",
    "            word = line_vals[0]\n",
    "            if word.isalpha():\n",
    "                vector = np.asarray(line_vals[1:], \"float32\")\n",
    "                word2vec[word] = vector\n",
    "\n",
    "    return word2vec\n",
    "\n",
    "\n",
    "def get_embedding_mat(word2vec, tokenizer, vocab_size, dim):\n",
    "    embedding_mat = np.random.rand(vocab_size, dim)\n",
    "    for word, ind in tokenizer.word_index.items():\n",
    "        vec = word2vec.get(word)\n",
    "        if vec is not None:\n",
    "            embedding_mat[ind] = vec\n",
    "\n",
    "    return embedding_mat\n",
    "\n",
    "\n",
    "def get_vocab_size(df):\n",
    "    lyrics = df[\"lyrics\"].str.cat()\n",
    "    words = lyrics.replace(\"sfin\", \"\").split(\" \")\n",
    "    vocab = set(words)\n",
    "\n",
    "    return len(vocab) + 1  # Added 1 for unknown word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for loading the midi data and vectorizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_midi_dict(path):\n",
    "    midi_dict = {}\n",
    "    for file_name in os.listdir(path):\n",
    "        temp = \"\" + file_name\n",
    "        file_name = file_name[:-4].lower()\n",
    "        artist, title = file_name.replace(\"_\", \" \").split(\"-\", maxsplit=1)\n",
    "        if \"-\" in title:\n",
    "            title = title.split(\"-\", maxsplit=1)[0]  # To clean song name\n",
    "        artist = artist.strip()\n",
    "        title = title.strip()\n",
    "        midi_dict[(artist, title)] = temp\n",
    "\n",
    "    return midi_dict\n",
    "\n",
    "\n",
    "def load_midi_file(file_name):\n",
    "    midi = None\n",
    "    try:\n",
    "        midi = pretty_midi.PrettyMIDI(os.path.join(MIDI_PATH, file_name))\n",
    "    except:\n",
    "        print(f\"Unable to create PrettyMIDI object from the song {file_name}\")\n",
    "\n",
    "    return midi\n",
    "\n",
    "\n",
    "def get_midi_vec(midi_data):\n",
    "    bpm = np.array([midi_data.estimate_tempo() / 360])\n",
    "    chroma = np.array(midi_data.get_chroma().sum(axis=1) / midi_data.get_chroma().sum())\n",
    "    pitch_hist = np.array(midi_data.get_pitch_class_histogram())\n",
    "    piano_roll = np.array(midi_data.get_piano_roll().sum(axis=1) / midi_data.get_piano_roll().sum())\n",
    "    pitch_mat = np.array(midi_data.get_pitch_class_transition_matrix(normalize=True)).reshape(-1)\n",
    "\n",
    "    full_vector = np.hstack((bpm, chroma, pitch_hist, piano_roll, pitch_mat))\n",
    "    np.nan_to_num(x=full_vector, copy=False)  # Replace NaN values with 0.0\n",
    "\n",
    "    return full_vector\n",
    "\n",
    "\n",
    "def create_midi_df(midi_dict):\n",
    "    temp = {\"artist-title\": [], \"vector\": []}\n",
    "    for key, value in midi_dict.items():\n",
    "        pm = load_midi_file(value)\n",
    "        if pm is not None:\n",
    "            name = str(key[0]) + \"-\" + str(key[1])\n",
    "            temp[\"artist-title\"].append(name)\n",
    "            temp[\"vector\"].append(get_midi_vec(pm))\n",
    "    midi_df = pd.DataFrame.from_dict(temp)\n",
    "\n",
    "    return midi_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(features, labels, seq_indices, midi_data):\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    train_midis = []\n",
    "    val_features = []\n",
    "    val_labels = []\n",
    "    val_midis = []\n",
    "\n",
    "    inds = list(seq_indices.keys())\n",
    "    random_indices = random.choices(inds, k=len(inds) // 5)\n",
    "\n",
    "    for ind in inds:\n",
    "        if ind not in random_indices:\n",
    "            for i in seq_indices[ind]:\n",
    "                train_features.append(features[i])\n",
    "                train_labels.append(labels[i])\n",
    "                train_midis.append(midi_data[ind])\n",
    "        else:\n",
    "            for i in seq_indices[ind]:\n",
    "                val_features.append(features[i])\n",
    "                val_labels.append(labels[i])\n",
    "                val_midis.append(midi_data[ind])\n",
    "\n",
    "    return (\n",
    "        np.array(train_features),\n",
    "        np.array(train_labels),\n",
    "        np.array(train_midis),\n",
    "        np.array(val_features),\n",
    "        np.array(val_labels),\n",
    "        np.array(val_midis),\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_model(vocab_size, embedding_mat, max_seq_size, midi_vec_size):\n",
    "    lyrics_input = Input((max_seq_size,))\n",
    "    midi_input = Input((midi_vec_size,))\n",
    "\n",
    "    embed_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=WORD_DIM,\n",
    "        weights=[embedding_mat],\n",
    "        input_length=max_seq_size,\n",
    "        trainable=False,\n",
    "    )(lyrics_input)\n",
    "    lstm_layer = Bidirectional(LSTM(units=8))(embed_layer)\n",
    "    concat_layer = Concatenate(axis=-1)([midi_input, lstm_layer])\n",
    "    output_layer = Dense(vocab_size, activation=\"softmax\")(concat_layer)\n",
    "\n",
    "    model = Model(inputs=[lyrics_input, midi_input], outputs=output_layer)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Creates the advanced model\n",
    "def get_advanced_model(vocab_size, embedding_mat, max_seq_size, midi_vec_size):\n",
    "    lyrics_input = Input((max_seq_size,))\n",
    "    midi_input = Input((midi_vec_size,))\n",
    "\n",
    "    embed_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=WORD_DIM,\n",
    "        weights=[embedding_mat],\n",
    "        input_length=max_seq_size,\n",
    "        trainable=False,\n",
    "    )(lyrics_input)\n",
    "    midi_reshape = Reshape((1, -1))(midi_input)\n",
    "    lstm_layer1midi = Bidirectional(LSTM(units=128, return_sequences=True))(midi_reshape)\n",
    "    lstm_layer2midi = Bidirectional(LSTM(units=128))(lstm_layer1midi)\n",
    "    lstm_layer1 = Bidirectional(LSTM(units=128, return_sequences=True))(embed_layer)\n",
    "    lstm_layer2 = Bidirectional(LSTM(units=128))(lstm_layer1)\n",
    "    concat_layer = Concatenate(axis=-1)([lstm_layer2midi, lstm_layer2])\n",
    "    dense_layer = Dense(1024, activation=\"relu\")(concat_layer)\n",
    "    dropout_layer = Dropout(0.3)(dense_layer)\n",
    "    output_layer = Dense(vocab_size, activation=\"softmax\")(dropout_layer)\n",
    "\n",
    "    model = Model(inputs=[lyrics_input, midi_input], outputs=output_layer)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(TRAIN_PATH)\n",
    "df[\"artist-title\"] = df.apply(lambda row: str(row[\"artist\"]) + \"-\" + str(row[\"title\"]), axis=1)\n",
    "df[\"lyrics\"] = df[\"lyrics\"].apply(lambda row: row.replace(\"&\", \" sfin \"))\n",
    "\n",
    "midi_dict = get_midi_dict(MIDI_PATH)\n",
    "\n",
    "try:\n",
    "    midi_df = pd.read_pickle(MIDI_PKL_PATH)\n",
    "except:\n",
    "    midi_df = create_midi_df(midi_dict)\n",
    "    midi_df.to_pickle(MIDI_PKL_PATH)\n",
    "\n",
    "\n",
    "merged_df = pd.merge(df, midi_df, how=\"inner\", on=\"artist-title\")\n",
    "\n",
    "vocab_size = get_vocab_size(merged_df)\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(merged_df[\"lyrics\"].tolist())\n",
    "sequences = tokenizer.texts_to_sequences(merged_df[\"lyrics\"].tolist())\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "seq_indices = {}\n",
    "seq_list = []\n",
    "\n",
    "count = 0\n",
    "for ind, sequence in enumerate(sequences):\n",
    "    seq_indices[ind] = []\n",
    "    for j in range(1, len(sequence)):\n",
    "        for z in range(MAX_SEQUENCE_LENGTH):\n",
    "            seq = sequence[j : j + z + 2]\n",
    "            seq_list.append(np.array(seq))\n",
    "            seq_indices[ind].append(count)\n",
    "            count += 1\n",
    "\n",
    "max_seq_len = max([len(seq) for seq in seq_list])\n",
    "padded_sequences = pad_sequences(seq_list, maxlen=max_seq_len, padding=\"pre\")\n",
    "padded_sequences = np.array(padded_sequences)\n",
    "\n",
    "features = padded_sequences[:, :-1]\n",
    "labels = padded_sequences[:, -1]\n",
    "midi_data = merged_df[\"vector\"].values\n",
    "\n",
    "word2vec = load_glove(GLOVE_PATH)\n",
    "embed_mat = get_embedding_mat(word2vec, tokenizer, vocab_size, WORD_DIM)\n",
    "\n",
    "\n",
    "train_features, train_labels, train_midis, val_features, val_labels, val_midis = train_val_split(\n",
    "    features, labels, seq_indices, midi_data\n",
    ")\n",
    "\n",
    "# Only the piano roll portion of the midi vector\n",
    "simple_midis = np.array([midi[25:-144] for midi in train_midis])\n",
    "simple_val_midis = np.array([midi[25:-144] for midi in val_midis])\n",
    "\n",
    "simple_model = get_simple_model(vocab_size, embed_mat, MAX_SEQUENCE_LENGTH, simple_midis.shape[1])\n",
    "\n",
    "adv_model = get_advanced_model(vocab_size, embed_mat, MAX_SEQUENCE_LENGTH, train_midis.shape[1])\n",
    "\n",
    "simple_model.fit(\n",
    "    [train_features, simple_midis],\n",
    "    train_labels,\n",
    "    batch_size=256,\n",
    "    epochs=1,\n",
    "    validation_data=([val_features, simple_val_midis], val_labels),\n",
    ")\n",
    "\n",
    "adv_model.fit(\n",
    "    [train_features, train_midis],\n",
    "    train_labels,\n",
    "    batch_size=256,\n",
    "    epochs=1,\n",
    "    validation_data=([val_features, val_midis], val_labels),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for word prediction, lyrics generating and printing songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts the next word\n",
    "def predict_word(model, sequence, midi_data):\n",
    "    word_amount = 4\n",
    "    pred_words = model.predict([np.array(sequence).reshape(1, -1), midi_data.reshape(1, -1)], verbose = 0)\n",
    "    # Chooses a word_amount of the best words\n",
    "    best_words = (-pred_words[0]).argsort()[:word_amount]\n",
    "    # Gets the prob for each of the best words\n",
    "    best_probs = pred_words[0][best_words]\n",
    "    # Normalizes the prob of the best words\n",
    "    norm_probs = [prob / sum(best_probs) for prob in best_probs]\n",
    "    # Chooses a random word out of the best words, based on their probs\n",
    "    chosen_word = np.random.choice(best_words, 1, p=norm_probs)[0]\n",
    "\n",
    "    return chosen_word\n",
    "\n",
    "\n",
    "# Generates lyrics by using the model to predict the next word\n",
    "def generate_lyrics(model, initial_word, midi_data, lyrics_length):\n",
    "    pred_sentence = []\n",
    "    pred_sentence.append(initial_word)\n",
    "    input_sequence = np.zeros(MAX_SEQUENCE_LENGTH)\n",
    "    input_sequence[-1] = initial_word\n",
    "    for _ in range(lyrics_length - 1):\n",
    "        next_word = predict_word(model, input_sequence, midi_data)\n",
    "        input_sequence = np.roll(input_sequence, -1)\n",
    "        input_sequence[-1] = next_word\n",
    "        pred_sentence.append(next_word)\n",
    "\n",
    "    return pred_sentence\n",
    "\n",
    "\n",
    "# Prints a song\n",
    "def print_song(song, midi_ind):\n",
    "    for seq in song:\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(f\"Song starts with '{seq[0].split(' ')[0]}', melody #{midi_ind+1}: \")\n",
    "        for sentence in seq:\n",
    "            print(sentence.strip())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating lyrics based on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the test set\n",
    "test_df = load_dataset(TEST_PATH)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df[\"lyrics\"].tolist())\n",
    "\n",
    "# Chooses 3 initial words\n",
    "test_input_lyrics = [seq[0] for seq in test_sequences]\n",
    "test_input_lyrics = random.sample(test_input_lyrics, k=3)\n",
    "\n",
    "# Gets the vectorized form of each midi file\n",
    "test_input_midis = []\n",
    "for row in test_df.itertuples():\n",
    "    try:\n",
    "        artist_title = str(row[1]).strip() + \"-\" + str(row[2]).strip()\n",
    "        test_input_midis.append(\n",
    "            midi_df.loc[midi_df[\"artist-title\"] == artist_title, \"vector\"].squeeze()\n",
    "        )\n",
    "    except:\n",
    "        test_input_midis.append(None)\n",
    "\n",
    "# Takes only part of the vector (piano roll) for the simple model\n",
    "simple_test_midis = [midi[25:-144] for midi in test_input_midis]\n",
    "\n",
    "LYRICS_PER_SONG = 112\n",
    "texts_smp = []\n",
    "texts_adv = []\n",
    "songs_smp = []\n",
    "songs_adv = []\n",
    "\n",
    "# Generating the lyrics using the trained models\n",
    "for melody in range(len(test_input_midis)):\n",
    "    lyrics_smp = []\n",
    "    lyrics_adv = []\n",
    "    for init_word in range(len(test_input_lyrics)):\n",
    "        lyrics_smp.append(\n",
    "            generate_lyrics(\n",
    "                simple_model, test_input_lyrics[init_word], simple_test_midis[melody], lyrics_length=LYRICS_PER_SONG\n",
    "            )\n",
    "        )\n",
    "        lyrics_adv.append(\n",
    "            generate_lyrics(\n",
    "                adv_model, test_input_lyrics[init_word], test_input_midis[melody], lyrics_length=LYRICS_PER_SONG\n",
    "            )\n",
    "        )\n",
    "    texts_smp.append(tokenizer.sequences_to_texts(np.array(lyrics_smp)))\n",
    "    texts_adv.append(tokenizer.sequences_to_texts(np.array(lyrics_adv)))\n",
    "\n",
    "# Seperate the lyrics to sentences\n",
    "for melody in range(len(test_input_midis)):\n",
    "    songs_smp.append([text.split(\"sfin\") for text in texts_smp[melody]])\n",
    "    songs_adv.append([text.split(\"sfin\") for text in texts_adv[melody]])\n",
    "\n",
    "# Print the songs generated by the simple model\n",
    "print(\"************************SIMPLE SONGS*****************************\")\n",
    "for i, song in enumerate(songs_smp):\n",
    "    print_song(song, i)\n",
    "\n",
    "# Print the songs generated by the advanced model\n",
    "print(\"************************ADVANCED SONGS*****************************\")\n",
    "for i, song in enumerate(songs_adv):\n",
    "    print_song(song, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
